{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a59e38a4-3179-40bd-9ca7-5cea75f1bb2a",
   "metadata": {},
   "source": [
    "# **Explain Like I'm Not a Scientist**\n",
    "### *An exploration of (not so) scientific communication*\n",
    "| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |\n",
    "|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|Emily K. Sanders| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |Project 3: NLP|\n",
    "|DSB-318| | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | | |May 3, 2024|\n",
    "---\n",
    "###### *A report for the 2024 Greater Lafayette Association for Data Science Conference on Activism for a Thriving Society*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e7d63-2fec-4bf3-8295-4774a33ee9cc",
   "metadata": {},
   "source": [
    "## Prior Notebooks Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e21cb0-2e72-4f41-8a76-d73f916e1595",
   "metadata": {},
   "source": [
    "In the previous 2 notebooks, I introduced the purpose of this work and summarized relevant background information, then gave an overview of the Method section up to the end of scraping the posts.\n",
    "\n",
    "In this notebook, I will demonstrate how I scraped the comments of these posts, including `python` code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d5d0f-9aa7-4225-b9bd-744342d03d2b",
   "metadata": {},
   "source": [
    "## Method: Scraping procedure for comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616c9a4-c4c1-47a3-bde9-b1c5510cf252",
   "metadata": {},
   "source": [
    "Below is the syntax I used to scrape the comments for each post.  Where it is the same as the syntax for scraping the posts, it is presented without further elaboration.  Where it is different, I have explained why.\n",
    "\n",
    "The note and attribution from the previous notebook apply here too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70c961b-28db-4f82-9bef-727ed7a40e15",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "91b749ee-02a9-41c4-b46b-f57ab8d9e654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import getpass\n",
    "from datetime import date, time, datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dca6c9-9eb4-46b2-a44c-8ffd4f5ca08a",
   "metadata": {},
   "source": [
    "### Getting Authorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef381834-36af-4be5-9acc-11dd0a51273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter authorization keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f6f462ff-1f68-460c-975e-39a83ce21edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "client_id = getpass.getpass() # Listed as \"personal use script\" in your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e87ece17-8ccc-49cb-a965-feb54d406e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "client_secret = getpass.getpass() # Listed as \"secret\" in your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "272ad7a7-6f25-4b50-b7b5-cadff4f5d2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "user_agent = getpass.getpass() # The name of your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b6c10e33-4b50-43bd-85bc-5078728e698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "username = getpass.getpass() # The reddit username associated with your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3e46a8aa-d316-4437-9b50-861b46f0941d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "password = getpass.getpass() # The reddit password associated with your application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d21db33c-c41a-41aa-83ab-4ae53b748158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial hook-in was successful? True\n"
     ]
    }
   ],
   "source": [
    "# Authorize\n",
    "auth = requests.auth.HTTPBasicAuth(client_id, client_secret)\n",
    "\n",
    "# Set up authorization dictionary\n",
    "data = {\n",
    "  'grant_type': 'password','username': username, 'password': password}\n",
    "\n",
    "# Create a header for scrapes - please change this value if replicating!\n",
    "headers = {'User-Agent': 'EKS-DSB-318/Project-3'}\n",
    "\n",
    "# Connect to the reddit API\n",
    "res = requests.post(\n",
    "    'https://www.reddit.com/api/v1/access_token',\n",
    "    auth=auth, data=data, headers=headers)\n",
    "\n",
    "# Check the API connection\n",
    "print(f'The initial hook-in was successful? {res.status_code == 200}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "214a2802-96c8-4472-821f-7217104c7318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token is retrieved? True\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the access token\n",
    "token = res.json()['access_token']\n",
    "\n",
    "# Add the token to the headers\n",
    "headers['Authorization'] = f'bearer {token}'\n",
    "\n",
    "# Check that the token works\n",
    "print(\n",
    "  f'''The token is retrieved? {requests.get(\n",
    "  'https://oauth.reddit.com/api/v1/me', headers=headers).status_code == 200}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ae2a860-2875-415b-b3e3-d6abc3d5c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define things for the requests - static\n",
    "base_url = 'https://oauth.reddit.com'\n",
    "subreddit1 = '/r/explainlikeimfive' \n",
    "subreddit2 = '/r/askphysics'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b88bd-bcaa-4dad-81eb-0cab2cb61e5f",
   "metadata": {},
   "source": [
    "## Comments: Data In"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a09d1a-6ccd-4288-bbae-bbca75d5d8d1",
   "metadata": {},
   "source": [
    "This is where the paths diverge.  Whereas posts can be scraped from the subreddit in large batches, comments must be scraped from each individual post on which they were left.  This meant that rather than doing a `while` loop with a few iterations, I had to iterate through each individual post and place a separate `get` request for its comments.  Despite this difference, the syntax of the loop is very similar to the previous one, and is therefore presented with fewer annotations.  For the purpose of demonstration, I have imported the CSV created in the last notebook and processed it in this way.  In the \"behind-the-scenes\" work, this was the combined dataframe of all of the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7612ae5e-aadb-4018-9ad8-340ea043e40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 110)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataframe of posts\n",
    "scrapes = pd.read_csv('../data/output/concatted-wholes/combined-as-of_2024-05-02_h23-m28-s15.csv')\n",
    "scrapes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0622dc1b-fb2a-42d4-b59e-5b956ca3b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholder lists\n",
    "askp_comments_scrapes = []\n",
    "eli5_comments_scrapes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "76b3ea78-4c04-4efa-8df3-45b428a924ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post 1cd9r3s complete\n",
      "post 1cddwhq complete\n",
      "post 1cdlxli complete\n",
      "post 1cd1hxh complete\n",
      "post 1cdrrks complete\n",
      "post 1cdnk4p complete\n",
      "post 1cbyfa1 complete\n",
      "post 1cdrdus complete\n"
     ]
    }
   ],
   "source": [
    "# Iteratively request each post's comments\n",
    "for i in scrapes.index:\n",
    "  link = scrapes.loc[i, 'permalink']  # identify the correct link\n",
    "  sub = scrapes.loc[i, 'source']  # identify which subreddit it came from\n",
    "  comments = requests.get(base_url+link, headers=headers)\n",
    "  if sub=='eli5':\n",
    "    eli5_comments_scrapes.append(comments.json())\n",
    "  elif sub=='askp':\n",
    "    askp_comments_scrapes.append(comments.json())\n",
    "  print(f\"post {scrapes.loc[i, 'id']} complete\")\n",
    "  time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342c4a45-0969-4eda-ade2-57a7942b97a5",
   "metadata": {},
   "source": [
    "As with the posts, at the end of running that code, I had two lists full of dictionaries, themselves full of more dictionaries, corresponding to the comments of one post each.  Before ending the `python` session, I again needed to export this data to external files for storage. This was a very similar process as it was for the posts, but it required a few modifications to the `post_csvs()` function (adding a \"comment\" indicator), and allowed for a slight simplification of the `for` loop because each scrape only contained one dictionary of information, rather than 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9edb10-b9c3-4e9e-8032-5f65acf6e68a",
   "metadata": {},
   "source": [
    "## Comments: Data Out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5eeec4-eb6f-49df-9273-96866cfbb14f",
   "metadata": {},
   "source": [
    "Like the posts, the comments were saved as `JSON`-turned-dictionary objects and needed some coercing into dataframes that could be exported to CSVs for storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "36711056-02b5-4060-991c-017189b72e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a useful function\n",
    "def be_kind(df):\n",
    "    \"\"\"Double check that there's only one 'kind' per scrape,\n",
    "    then streamline the resulting dataframe.\n",
    "    \n",
    "    Arg: {df}, a dataframe created from a scrape from the reddit API\n",
    "    Return: {df}, the same dataframe, altered\n",
    "    Raise: nothing so far! It would raise all sorts of errors if \n",
    "    applied to a different kind of dataframe, though.\"\"\"\n",
    "\n",
    "    # If it's just the one value\n",
    "    if len(df.loc[:,'kind'].unique())==1:\n",
    "        # Create a new row in the 'data' column and populate it\n",
    "        # with whatever's in the 'kind' column\n",
    "        df.loc['kind','data'] = df.loc[:,'kind'].unique()[0]\n",
    "        # Get rid of the ['kind'] column\n",
    "        df.drop(columns = 'kind', inplace = True)       \n",
    "    # If there's more than one (this never happened)\n",
    "    else:\n",
    "        # Tell me, then stop\n",
    "        print(f'multiple kinds in {i}')\n",
    "    # Return\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3b9e1ed7-2c59-4c05-8139-4fc90f6abb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03_h05-m39-s21\n"
     ]
    }
   ],
   "source": [
    "# Define a useful functions\n",
    "def my_date():\n",
    "  return datetime.now().strftime('%Y-%m-%d_h%H-m%M-s%S')\n",
    "print(my_date()) # test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "83ff4d24-7d0e-47de-9a86-ba6f3648af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a useful function\n",
    "def post_csvs(l, df, k2, i):\n",
    "    '''Convert the dataframes of scrapes into meaningfully-named CSVs.\n",
    "    Requires `my_date()` to also be defined.\n",
    "  \n",
    "    Arg:\n",
    "        l: the storage list the df came from; a proxy for the subreddit\n",
    "        df: the dataframe to be converted\n",
    "        k2: my per-subreddit counter\n",
    "        i: the individual post counter\n",
    "    Return:\n",
    "        df in the environment\n",
    "        a CSV file saved to the working directory\n",
    "    Raise:\n",
    "        fingers crossed'''\n",
    "    \n",
    "    # Use l to create text names\n",
    "    if l == askp_comments_scrapes:\n",
    "        sub = 'askp-comments'\n",
    "    if l == eli5_comments_scrapes:\n",
    "        sub = 'eli5-comments'\n",
    "    # Bypass that weird copy thing\n",
    "    # Transpose the dataframe so each scrape is a row, not a column\n",
    "    df2 = df.copy(deep = True).transpose()\n",
    "    # Make the first row the column names\n",
    "    df2.columns = list(df2.iloc[0,:])\n",
    "    # Drop an unnecessary column that appears after multiple merges\n",
    "    if i>0:\n",
    "        df2.drop(index = 'key_0', inplace = True)\n",
    "    # Assign meaningful names (source, datetime, scrape iteration) and write to CSV\n",
    "    df2.to_csv(f'../data/output/comments/{sub}_{my_date()}_scrape{k2}.csv')\n",
    "    # Return\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "60810ebf-4c3e-4cde-b9a1-e0e41435b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for l in [askp_comments_scrapes, eli5_comments_scrapes]:\n",
    "  print(len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df32493b-60c5-41d2-a3b7-d1d8dc66f4ab",
   "metadata": {},
   "source": [
    "**Note:** Because this cell has already been run for demonstration purposes, and thus already produced files in the `data/output/comments` folder, **future cells that draw from that folder will produce different results if run again.**  To replicate the results, please fork the repository, **delete** the contents of `data/output/comments`, and then try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c3cd049c-a0c1-4a8f-be5f-260c90e6a0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done, 8 posts processed\n"
     ]
    }
   ],
   "source": [
    "# Set an overall counter\n",
    "k=0\n",
    "# For each set of scrapes\n",
    "for l in [askp_comments_scrapes, eli5_comments_scrapes]: \n",
    "    # Set a per-subreddit counter\n",
    "    k2=0\n",
    "    # For each scrape\n",
    "    for p in l:\n",
    "        # Count\n",
    "        k+=1\n",
    "        j = p[1]['data']['children'] \n",
    "        # For each individual post scraped, note how much \"digging\" occurs here\n",
    "        for i in list(range(len(j))):\n",
    "            # If it's the first one we're processing\n",
    "            if i==0:\n",
    "                # It gets its own dataframe made of its dictionary\n",
    "                x = pd.DataFrame(j[i])\n",
    "                # Handle the 'kind' column\n",
    "                x = be_kind(x)               \n",
    "            # If it's not the first one\n",
    "            else:\n",
    "                # It becomes a dataframe with a different name\n",
    "                y = pd.DataFrame(j[i])\n",
    "                # Handle the 'kind' column\n",
    "                y = be_kind(y)               \n",
    "                # Merge the dataframes together\n",
    "                if i==1:\n",
    "                    x = x.merge(y, how = 'outer', left_on = x.index, right_on = y.index, suffixes = [None, f'_{i}'])\n",
    "                elif i>1:\n",
    "                    x = x.merge(y, how = 'outer', left_on = 'key_0', right_on = y.index, suffixes = [None, f'_{i}'])\n",
    "            # Count\n",
    "            k2+=1\n",
    "        # Tidy up the dataframe, write to CSV\n",
    "        x = post_csvs(l, x, k2, i)\n",
    "print(f'All done, {k} posts processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfc1571-98b9-4dbf-8834-c672c2e0121e",
   "metadata": {},
   "source": [
    "Below is the resulting dataframe, `x`, at the end of that loop.  As with the posts, `x` is still overwritten each time the loop cycles through a set of scrapes, but its lentgh is now variable for each scrape.  This `x` corresponds to only one post, but has 4 rows because that post received 4 top level comments.  As can be seen in the `['replies']` columns, two of those comments received further sub-comments, and two of them did not.  Early on in the project I extracted many of the sub-comments, and I would be happy to make them available to other scholars.  However, due to time and computing constraints, they were not included in the current work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "deb21b21-f927-4b79-9cfe-ce08fe6e143e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>awarders</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>collapsed_because_crowd_control</th>\n",
       "      <th>collapsed_reason</th>\n",
       "      <th>collapsed_reason_code</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>depth</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>gildings</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>likes</th>\n",
       "      <th>link_id</th>\n",
       "      <th>locked</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>name</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>replies</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>unrepliable_reason</th>\n",
       "      <th>ups</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>ezekielraiden</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_16nhu9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>It depends what you mean by \"completely voided...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;It depends what...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1714153061.0</td>\n",
       "      <td>1714153061.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1drwig</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1drwig</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>/r/explainlikeimfive/comments/1cdrdus/eli5_wha...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'kind': 'Listing', 'data': {'after': None, 'd...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>t5_2sokd</td>\n",
       "      <td>r/explainlikeimfive</td>\n",
       "      <td>public</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_1</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>TheJeeronian</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3spgt7bd</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Under normal use a tank will not be completely...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;Under normal us...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1714152968.0</td>\n",
       "      <td>1714152968.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1drmne</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1drmne</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>/r/explainlikeimfive/comments/1cdrdus/eli5_wha...</td>\n",
       "      <td>None</td>\n",
       "      <td>{'kind': 'Listing', 'data': {'after': None, 'd...</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>t5_2sokd</td>\n",
       "      <td>r/explainlikeimfive</td>\n",
       "      <td>public</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_2</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>DBDude</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_9eu97</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>It's not empty. It's just gas at the same pres...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;It&amp;amp;#39;s no...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1714154977.0</td>\n",
       "      <td>1714154977.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1dxlee</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1dxlee</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>/r/explainlikeimfive/comments/1cdrdus/eli5_wha...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>t5_2sokd</td>\n",
       "      <td>r/explainlikeimfive</td>\n",
       "      <td>public</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_3</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>kanakamaoli</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_egn6g</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Empty gas tanks may still have a small amount ...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;Empty gas tanks...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1714181528.0</td>\n",
       "      <td>1714181528.0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1fwaud</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1fwaud</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>t3_1cdrdus</td>\n",
       "      <td>/r/explainlikeimfive/comments/1cdrdus/eli5_wha...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>t5_2sokd</td>\n",
       "      <td>r/explainlikeimfive</td>\n",
       "      <td>public</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       all_awardings approved_at_utc approved_by archived associated_award  \\\n",
       "data              []            None        None    False             None   \n",
       "data_1            []            None        None    False             None   \n",
       "data_2            []            None        None    False             None   \n",
       "data_3            []            None        None    False             None   \n",
       "\n",
       "               author author_flair_background_color author_flair_css_class  \\\n",
       "data    ezekielraiden                          None                   None   \n",
       "data_1   TheJeeronian                          None                   None   \n",
       "data_2         DBDude                          None                   None   \n",
       "data_3    kanakamaoli                          None                   None   \n",
       "\n",
       "       author_flair_richtext author_flair_template_id author_flair_text  \\\n",
       "data                      []                     None              None   \n",
       "data_1                    []                     None              None   \n",
       "data_2                    []                     None              None   \n",
       "data_3                    []                     None              None   \n",
       "\n",
       "       author_flair_text_color author_flair_type author_fullname  \\\n",
       "data                      None              text       t2_16nhu9   \n",
       "data_1                    None              text     t2_3spgt7bd   \n",
       "data_2                    None              text        t2_9eu97   \n",
       "data_3                    None              text        t2_egn6g   \n",
       "\n",
       "       author_is_blocked author_patreon_flair author_premium awarders  \\\n",
       "data               False                False          False       []   \n",
       "data_1             False                False          False       []   \n",
       "data_2             False                False          False       []   \n",
       "data_3             False                False          False       []   \n",
       "\n",
       "       banned_at_utc banned_by  \\\n",
       "data            None      None   \n",
       "data_1          None      None   \n",
       "data_2          None      None   \n",
       "data_3          None      None   \n",
       "\n",
       "                                                     body  \\\n",
       "data    It depends what you mean by \"completely voided...   \n",
       "data_1  Under normal use a tank will not be completely...   \n",
       "data_2  It's not empty. It's just gas at the same pres...   \n",
       "data_3  Empty gas tanks may still have a small amount ...   \n",
       "\n",
       "                                                body_html can_gild  \\\n",
       "data    &lt;div class=\"md\"&gt;&lt;p&gt;It depends what...    False   \n",
       "data_1  &lt;div class=\"md\"&gt;&lt;p&gt;Under normal us...    False   \n",
       "data_2  &lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s no...    False   \n",
       "data_3  &lt;div class=\"md\"&gt;&lt;p&gt;Empty gas tanks...    False   \n",
       "\n",
       "       can_mod_post collapsed collapsed_because_crowd_control  \\\n",
       "data          False     False                            None   \n",
       "data_1        False     False                            None   \n",
       "data_2        False     False                            None   \n",
       "data_3        False     False                            None   \n",
       "\n",
       "       collapsed_reason collapsed_reason_code comment_type controversiality  \\\n",
       "data               None                  None         None                0   \n",
       "data_1             None                  None         None                0   \n",
       "data_2             None                  None         None                0   \n",
       "data_3             None                  None         None                0   \n",
       "\n",
       "             created   created_utc depth distinguished downs edited gilded  \\\n",
       "data    1714153061.0  1714153061.0     0          None     0  False      0   \n",
       "data_1  1714152968.0  1714152968.0     0          None     0  False      0   \n",
       "data_2  1714154977.0  1714154977.0     0          None     0  False      0   \n",
       "data_3  1714181528.0  1714181528.0     0          None     0  False      0   \n",
       "\n",
       "       gildings       id is_submitter likes     link_id locked mod_note  \\\n",
       "data         {}  l1drwig        False  None  t3_1cdrdus  False     None   \n",
       "data_1       {}  l1drmne        False  None  t3_1cdrdus  False     None   \n",
       "data_2       {}  l1dxlee        False  None  t3_1cdrdus  False     None   \n",
       "data_3       {}  l1fwaud        False  None  t3_1cdrdus  False     None   \n",
       "\n",
       "       mod_reason_by mod_reason_title mod_reports        name no_follow  \\\n",
       "data            None             None          []  t1_l1drwig     False   \n",
       "data_1          None             None          []  t1_l1drmne     False   \n",
       "data_2          None             None          []  t1_l1dxlee      True   \n",
       "data_3          None             None          []  t1_l1fwaud      True   \n",
       "\n",
       "       num_reports   parent_id  \\\n",
       "data          None  t3_1cdrdus   \n",
       "data_1        None  t3_1cdrdus   \n",
       "data_2        None  t3_1cdrdus   \n",
       "data_3        None  t3_1cdrdus   \n",
       "\n",
       "                                                permalink removal_reason  \\\n",
       "data    /r/explainlikeimfive/comments/1cdrdus/eli5_wha...           None   \n",
       "data_1  /r/explainlikeimfive/comments/1cdrdus/eli5_wha...           None   \n",
       "data_2  /r/explainlikeimfive/comments/1cdrdus/eli5_wha...           None   \n",
       "data_3  /r/explainlikeimfive/comments/1cdrdus/eli5_wha...           None   \n",
       "\n",
       "                                                  replies report_reasons  \\\n",
       "data    {'kind': 'Listing', 'data': {'after': None, 'd...           None   \n",
       "data_1  {'kind': 'Listing', 'data': {'after': None, 'd...           None   \n",
       "data_2                                                              None   \n",
       "data_3                                                              None   \n",
       "\n",
       "        saved score score_hidden send_replies stickied          subreddit  \\\n",
       "data    False    15        False         True    False  explainlikeimfive   \n",
       "data_1  False     6        False         True    False  explainlikeimfive   \n",
       "data_2  False     2        False         True    False  explainlikeimfive   \n",
       "data_3  False     1        False         True    False  explainlikeimfive   \n",
       "\n",
       "       subreddit_id subreddit_name_prefixed subreddit_type top_awarded_type  \\\n",
       "data       t5_2sokd     r/explainlikeimfive         public             None   \n",
       "data_1     t5_2sokd     r/explainlikeimfive         public             None   \n",
       "data_2     t5_2sokd     r/explainlikeimfive         public             None   \n",
       "data_3     t5_2sokd     r/explainlikeimfive         public             None   \n",
       "\n",
       "       total_awards_received treatment_tags unrepliable_reason ups  \\\n",
       "data                       0             []               None  15   \n",
       "data_1                     0             []               None   6   \n",
       "data_2                     0             []               None   2   \n",
       "data_3                     0             []               None   1   \n",
       "\n",
       "       user_reports kind  \n",
       "data             []   t1  \n",
       "data_1           []   t1  \n",
       "data_2           []   t1  \n",
       "data_3           []   t1  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24baa1-5067-4433-ac61-ea4d585f9a88",
   "metadata": {},
   "source": [
    "## Comments: Data Back In"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7cd26-7fa9-42ec-9b64-18bb91c355c0",
   "metadata": {},
   "source": [
    "The individual comments CSVs had to read in and concatenated just as the posts had.  Unfortunately, for reasons I was never able to pinpoint, some comments were exported without column headers, and a few became badly distorted, which caused problems upon re-importation.  Some of these also had two extra columns, but they were always unpopulated.  To work around this, I devised some tests to process smoothly the CSVs that could be, and to quarantine the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3b1efa47-ca30-4346-97b0-3654bda001c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the values that should always be in certain locations\n",
    "t61 = ['AskPhysics', 'explainlikeimfive']\n",
    "t62 = ['t5_2sumo', 't5_2sokd']\n",
    "t63 = ['r/AskPhysics', 'r/explainlikeimfive']\n",
    "\n",
    "# Define the tests\n",
    "tests = ( \n",
    "  (df.iloc[1,0]=='data') & (df.iloc[1,61] in t61) & (\n",
    "    df.iloc[1,62] in t62) & (df.iloc[1,63] in t63))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172ab84a-6333-47c3-aee6-21e8447b4c87",
   "metadata": {},
   "source": [
    "A few more tests, related to the number of columns in the CSVs were written directly into the loop.  Unfortunately, this required explicitly definining a list of the columns that were supposed to appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "18b1a2d4-be66-4933-972e-491086cb3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "com_col_names = [\n",
    "  'Unnamed: 0', 'all_awardings', 'approved_at_utc', 'approved_by', 'archived', 'associated_award', \n",
    "  'author', 'author_flair_background_color', 'author_flair_css_class', 'author_flair_richtext', \n",
    "  'author_flair_template_id', 'author_flair_text', 'author_flair_text_color', 'author_flair_type',\n",
    "  'author_fullname', 'author_is_blocked', 'author_patreon_flair', 'author_premium', 'awarders', \n",
    "  'banned_at_utc', 'banned_by', 'body','body_html', 'can_gild', 'can_mod_post', 'collapsed',\n",
    "  'collapsed_because_crowd_control', 'collapsed_reason', 'collapsed_reason_code', 'comment_type', \n",
    "  'controversiality', 'created', 'created_utc', 'depth', 'distinguished', 'downs', 'edited', \n",
    "  'gilded', 'gildings', 'id', 'is_submitter', 'likes', 'link_id', 'locked', 'mod_note', \n",
    "  'mod_reason_by', 'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_reports', \n",
    "  'parent_id', 'permalink', 'removal_reason', 'replies', 'report_reasons', 'saved', 'score', \n",
    "  'score_hidden', 'send_replies', 'stickied', 'subreddit', 'subreddit_id', \n",
    "  'subreddit_name_prefixed', 'subreddit_type', 'top_awarded_type', 'total_awards_received', \n",
    "  'treatment_tags', 'unrepliable_reason', 'ups', 'user_reports', 'kind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9d97ab33-f5e4-49be-aab7-87a9ff05b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CSVs to do\n"
     ]
    }
   ],
   "source": [
    "# Get a list of the CSVs\n",
    "previous_scrapes = os.listdir('../data/output/comments/')\n",
    "print(f\"{len(previous_scrapes)} CSVs to do\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2576c0-8bfa-40f9-bbd5-97661d4659c6",
   "metadata": {},
   "source": [
    "Below is the modified loop for reading in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "daca7e7b-d9f4-4957-b6e0-235355d3528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholder lists\n",
    "scrapes = [] # good CSVs\n",
    "trouble = [] # bad CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f032f634-bcc5-4996-aa7e-a5526f9a4537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 good CSVs\n",
      "2 bad CSVs\n"
     ]
    }
   ],
   "source": [
    "# Loop through the CSVs\n",
    "for file in previous_scrapes:\n",
    "  path = \"../data/output/comments/\" + file\n",
    "  df = pd.read_csv(path)\n",
    "  # Run tests\n",
    "  n = [col for col in df.columns if col not in com_col_names]\n",
    "  m = [col for col in com_col_names if col not in df.columns]\n",
    "  # For the problem CSVs\n",
    "  if ((len(n)!=len(m)) | (len(n)>1) | (len(m)>1)) & (len(df)!=2) & (tests==False):\n",
    "    # Create a list of numbers, convert to strings\n",
    "    x = list(range(len(df.columns)))\n",
    "    y = [str(b) for b in x]\n",
    "    # Read the CSV in again, suppress column names\n",
    "    df = pd.read_csv(path, header=0)\n",
    "    # Apply the numbers as column names\n",
    "    df.columns = y\n",
    "    # Put it in jail\n",
    "    trouble.append(df)\n",
    "  else:  # Otherwise do the normal stuff\n",
    "    file_name = file.split('.')[0] #drop the .csv\n",
    "    file_name = file_name.split('_') #break into chunks\n",
    "    df['source'] = file_name[0]\n",
    "    df['date_scraped'] = file_name[1]\n",
    "    df['scrape_num'] = file_name[-1]\n",
    "    scrapes.append(df)\n",
    "print(f'{len(scrapes)} good CSVs')\n",
    "print(f'{len(trouble)} bad CSVs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c29ccb-e1ba-4ac6-ac45-bde0a329e88e",
   "metadata": {},
   "source": [
    "Because the deformed CSVs always followed the same pattern, I was able to devise a standard process for dealing with them.  They had the correct columns in the correct order, and just needed the correct headers.  Some had extra columns, which needed a name for smoother processing, but were always blank and could be safely deleted.\n",
    "\n",
    "Unfortunately, because these dataframes had to be put through a different path without any column headers, they were not able to be marked with the information from their filenames.  Because of the limited number of posts, I was able to scrape all of the comments in the same day, and could therefore assign them the correct date manually.  (I will assign the same date here, even though these demonstration comments were  actually scraped whenever the notebook was last run.)  The `['source']` column could also be inferred, this time from the `['subreddit']` column that came prepackaged with the scrapes.  The scrape number, however, could not be retraced, and thus I filled it with \"unknown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "463b1f89-f9f6-4eea-b109-db149c78fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra column names\n",
    "com_col_names.append('source')\n",
    "com_col_names.append('date_scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547c042-962a-442e-ae64-1d9c9836c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the bad dataframes\n",
    "trouble = pd.concat(trouble, sort=False, axis=0, join='outer', ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4ade9d7d-4640-496e-9719-ce6f8dbbb75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 75)\n"
     ]
    }
   ],
   "source": [
    "# Add the column names\n",
    "trouble.columns = com_col_names\n",
    "\n",
    "# Add the 'scrape_num' column\n",
    "trouble['scrape_num'] = 'unknown'\n",
    "print(trouble.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "04806d26-7025-4dc4-8f04-b13597e4c411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>awarders</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>collapsed_because_crowd_control</th>\n",
       "      <th>collapsed_reason</th>\n",
       "      <th>collapsed_reason_code</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>depth</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>gildings</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>likes</th>\n",
       "      <th>link_id</th>\n",
       "      <th>locked</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>name</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>replies</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>unrepliable_reason</th>\n",
       "      <th>ups</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>kind</th>\n",
       "      <th>source</th>\n",
       "      <th>date_scraped</th>\n",
       "      <th>scrape_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ross_ns7f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_s7p2fdqk</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you don't understand astrophysics and QM, h...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;If you don&amp;amp;...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.714153e+09</td>\n",
       "      <td>1.714153e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1drmsx</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_1cdlxli</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1drmsx</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_1cdlxli</td>\n",
       "      <td>/r/AskPhysics/comments/1cdlxli/looking_for_par...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'kind': 'Listing', 'data': {'after': None, 'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskPhysics</td>\n",
       "      <td>t5_2sumo</td>\n",
       "      <td>r/AskPhysics</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 all_awardings  approved_at_utc  approved_by archived  \\\n",
       "0       data            []              NaN          NaN    False   \n",
       "\n",
       "   associated_award     author  author_flair_background_color  \\\n",
       "0               NaN  ross_ns7f                            NaN   \n",
       "\n",
       "   author_flair_css_class author_flair_richtext  author_flair_template_id  \\\n",
       "0                     NaN                    []                       NaN   \n",
       "\n",
       "   author_flair_text  author_flair_text_color author_flair_type  \\\n",
       "0                NaN                      NaN              text   \n",
       "\n",
       "  author_fullname author_is_blocked author_patreon_flair author_premium  \\\n",
       "0     t2_s7p2fdqk             False                False          False   \n",
       "\n",
       "  awarders  banned_at_utc  banned_by  \\\n",
       "0       []            NaN        NaN   \n",
       "\n",
       "                                                body  \\\n",
       "0  If you don't understand astrophysics and QM, h...   \n",
       "\n",
       "                                           body_html can_gild can_mod_post  \\\n",
       "0  &lt;div class=\"md\"&gt;&lt;p&gt;If you don&amp;...    False        False   \n",
       "\n",
       "  collapsed  collapsed_because_crowd_control  collapsed_reason  \\\n",
       "0     False                              NaN               NaN   \n",
       "\n",
       "   collapsed_reason_code  comment_type  controversiality       created  \\\n",
       "0                    NaN           NaN               0.0  1.714153e+09   \n",
       "\n",
       "    created_utc  depth  distinguished  downs edited  gilded gildings       id  \\\n",
       "0  1.714153e+09      0            NaN    0.0  False     0.0       {}  l1drmsx   \n",
       "\n",
       "  is_submitter  likes     link_id locked  mod_note  mod_reason_by  \\\n",
       "0        False    NaN  t3_1cdlxli  False       NaN            NaN   \n",
       "\n",
       "   mod_reason_title mod_reports        name no_follow  num_reports  \\\n",
       "0               NaN          []  t1_l1drmsx     False          NaN   \n",
       "\n",
       "    parent_id                                          permalink  \\\n",
       "0  t3_1cdlxli  /r/AskPhysics/comments/1cdlxli/looking_for_par...   \n",
       "\n",
       "   removal_reason                                            replies  \\\n",
       "0             NaN  {'kind': 'Listing', 'data': {'after': None, 'd...   \n",
       "\n",
       "   report_reasons  saved  score score_hidden send_replies stickied  \\\n",
       "0             NaN  False    4.0        False         True    False   \n",
       "\n",
       "    subreddit subreddit_id subreddit_name_prefixed subreddit_type  \\\n",
       "0  AskPhysics     t5_2sumo            r/AskPhysics         public   \n",
       "\n",
       "   top_awarded_type  total_awards_received treatment_tags  unrepliable_reason  \\\n",
       "0               NaN                    0.0             []                 NaN   \n",
       "\n",
       "   ups user_reports kind source  date_scraped scrape_num  \n",
       "0  4.0           []   t1    NaN           NaN    unknown  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply some rules to weed out \n",
    "trouble = trouble[trouble['all_awardings']=='[]']\n",
    "trouble = trouble[trouble['body'].notna()]\n",
    "print(trouble.shape)\n",
    "trouble.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "bacde405-7166-44a4-9c8c-333eccc0fe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>awarders</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>collapsed_because_crowd_control</th>\n",
       "      <th>collapsed_reason</th>\n",
       "      <th>collapsed_reason_code</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>depth</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>gildings</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>likes</th>\n",
       "      <th>link_id</th>\n",
       "      <th>locked</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>name</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>replies</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>unrepliable_reason</th>\n",
       "      <th>ups</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>kind</th>\n",
       "      <th>source</th>\n",
       "      <th>date_scraped</th>\n",
       "      <th>scrape_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mtauraso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>misc</td>\n",
       "      <td>[]</td>\n",
       "      <td>9a9f6614-c6b2-11e4-986d-22000bc08516</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3f8ok</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'd double check your units.  Just plugging va...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;I&amp;amp;#39;d dou...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1.714100e+09</td>\n",
       "      <td>1.714100e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1aocrt</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_1cd9r3s</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1aocrt</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_1cd9r3s</td>\n",
       "      <td>/r/AskPhysics/comments/1cd9r3s/keplers_constan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskPhysics</td>\n",
       "      <td>t5_2sumo</td>\n",
       "      <td>r/AskPhysics</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "      <td>askp-comments</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>scrape2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 all_awardings  approved_at_utc  approved_by  archived  \\\n",
       "0       data            []              NaN          NaN     False   \n",
       "\n",
       "   associated_award    author  author_flair_background_color  \\\n",
       "0               NaN  mtauraso                            NaN   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext  \\\n",
       "0                   misc                    []   \n",
       "\n",
       "               author_flair_template_id author_flair_text  \\\n",
       "0  9a9f6614-c6b2-11e4-986d-22000bc08516          Graduate   \n",
       "\n",
       "  author_flair_text_color author_flair_type author_fullname  \\\n",
       "0                    dark              text        t2_3f8ok   \n",
       "\n",
       "   author_is_blocked  author_patreon_flair  author_premium awarders  \\\n",
       "0              False                 False           False       []   \n",
       "\n",
       "   banned_at_utc  banned_by  \\\n",
       "0            NaN        NaN   \n",
       "\n",
       "                                                body  \\\n",
       "0  I'd double check your units.  Just plugging va...   \n",
       "\n",
       "                                           body_html  can_gild  can_mod_post  \\\n",
       "0  &lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d dou...     False         False   \n",
       "\n",
       "   collapsed  collapsed_because_crowd_control  collapsed_reason  \\\n",
       "0      False                              NaN               NaN   \n",
       "\n",
       "   collapsed_reason_code  comment_type  controversiality       created  \\\n",
       "0                    NaN           NaN                 0  1.714100e+09   \n",
       "\n",
       "    created_utc  depth  distinguished  downs edited  gilded gildings       id  \\\n",
       "0  1.714100e+09      0            NaN      0  False       0       {}  l1aocrt   \n",
       "\n",
       "   is_submitter  likes     link_id  locked  mod_note  mod_reason_by  \\\n",
       "0         False    NaN  t3_1cd9r3s   False       NaN            NaN   \n",
       "\n",
       "   mod_reason_title mod_reports        name  no_follow  num_reports  \\\n",
       "0               NaN          []  t1_l1aocrt      False          NaN   \n",
       "\n",
       "    parent_id                                          permalink  \\\n",
       "0  t3_1cd9r3s  /r/AskPhysics/comments/1cd9r3s/keplers_constan...   \n",
       "\n",
       "   removal_reason replies  report_reasons  saved  score  score_hidden  \\\n",
       "0             NaN     NaN             NaN  False      4         False   \n",
       "\n",
       "   send_replies  stickied   subreddit subreddit_id subreddit_name_prefixed  \\\n",
       "0          True     False  AskPhysics     t5_2sumo            r/AskPhysics   \n",
       "\n",
       "  subreddit_type  top_awarded_type  total_awards_received treatment_tags  \\\n",
       "0         public               NaN                      0             []   \n",
       "\n",
       "   unrepliable_reason  ups user_reports kind         source date_scraped  \\\n",
       "0                 NaN    4           []   t1  askp-comments   2024-05-03   \n",
       "\n",
       "  scrape_num  \n",
       "0    scrape2  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the good CSVs\n",
    "scrapes = pd.concat(scrapes, sort=False, axis=0, join='outer', ignore_index=True)\n",
    "print(scrapes.shape)\n",
    "scrapes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "de9d2de8-f07b-43ba-a143-b85c3e4018d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrapes is now a dataframe of dimensions (51, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>associated_award</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>author_flair_type</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>author_is_blocked</th>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <th>author_premium</th>\n",
       "      <th>awarders</th>\n",
       "      <th>banned_at_utc</th>\n",
       "      <th>banned_by</th>\n",
       "      <th>body</th>\n",
       "      <th>body_html</th>\n",
       "      <th>can_gild</th>\n",
       "      <th>can_mod_post</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>collapsed_because_crowd_control</th>\n",
       "      <th>collapsed_reason</th>\n",
       "      <th>collapsed_reason_code</th>\n",
       "      <th>comment_type</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>created</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>depth</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>downs</th>\n",
       "      <th>edited</th>\n",
       "      <th>gilded</th>\n",
       "      <th>gildings</th>\n",
       "      <th>id</th>\n",
       "      <th>is_submitter</th>\n",
       "      <th>likes</th>\n",
       "      <th>link_id</th>\n",
       "      <th>locked</th>\n",
       "      <th>mod_note</th>\n",
       "      <th>mod_reason_by</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>mod_reports</th>\n",
       "      <th>name</th>\n",
       "      <th>no_follow</th>\n",
       "      <th>num_reports</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>removal_reason</th>\n",
       "      <th>replies</th>\n",
       "      <th>report_reasons</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>score_hidden</th>\n",
       "      <th>send_replies</th>\n",
       "      <th>stickied</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>subreddit_type</th>\n",
       "      <th>top_awarded_type</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>treatment_tags</th>\n",
       "      <th>unrepliable_reason</th>\n",
       "      <th>ups</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>kind</th>\n",
       "      <th>source</th>\n",
       "      <th>date_scraped</th>\n",
       "      <th>scrape_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mtauraso</td>\n",
       "      <td>NaN</td>\n",
       "      <td>misc</td>\n",
       "      <td>[]</td>\n",
       "      <td>9a9f6614-c6b2-11e4-986d-22000bc08516</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>dark</td>\n",
       "      <td>text</td>\n",
       "      <td>t2_3f8ok</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'd double check your units.  Just plugging va...</td>\n",
       "      <td>&amp;lt;div class=\"md\"&amp;gt;&amp;lt;p&amp;gt;I&amp;amp;#39;d dou...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.714100e+09</td>\n",
       "      <td>1.714100e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{}</td>\n",
       "      <td>l1aocrt</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_1cd9r3s</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1_l1aocrt</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t3_1cd9r3s</td>\n",
       "      <td>/r/AskPhysics/comments/1cd9r3s/keplers_constan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>AskPhysics</td>\n",
       "      <td>t5_2sumo</td>\n",
       "      <td>r/AskPhysics</td>\n",
       "      <td>public</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>t1</td>\n",
       "      <td>askp-comments</td>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>scrape2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 all_awardings  approved_at_utc  approved_by archived  \\\n",
       "0       data            []              NaN          NaN    False   \n",
       "\n",
       "   associated_award    author  author_flair_background_color  \\\n",
       "0               NaN  mtauraso                            NaN   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext  \\\n",
       "0                   misc                    []   \n",
       "\n",
       "               author_flair_template_id author_flair_text  \\\n",
       "0  9a9f6614-c6b2-11e4-986d-22000bc08516          Graduate   \n",
       "\n",
       "  author_flair_text_color author_flair_type author_fullname author_is_blocked  \\\n",
       "0                    dark              text        t2_3f8ok             False   \n",
       "\n",
       "  author_patreon_flair author_premium awarders  banned_at_utc  banned_by  \\\n",
       "0                False          False       []            NaN        NaN   \n",
       "\n",
       "                                                body  \\\n",
       "0  I'd double check your units.  Just plugging va...   \n",
       "\n",
       "                                           body_html can_gild can_mod_post  \\\n",
       "0  &lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;d dou...    False        False   \n",
       "\n",
       "  collapsed  collapsed_because_crowd_control  collapsed_reason  \\\n",
       "0     False                              NaN               NaN   \n",
       "\n",
       "   collapsed_reason_code  comment_type  controversiality       created  \\\n",
       "0                    NaN           NaN               0.0  1.714100e+09   \n",
       "\n",
       "    created_utc  depth  distinguished  downs edited  gilded gildings       id  \\\n",
       "0  1.714100e+09      0            NaN    0.0  False     0.0       {}  l1aocrt   \n",
       "\n",
       "  is_submitter  likes     link_id locked  mod_note  mod_reason_by  \\\n",
       "0        False    NaN  t3_1cd9r3s  False       NaN            NaN   \n",
       "\n",
       "   mod_reason_title mod_reports        name no_follow  num_reports  \\\n",
       "0               NaN          []  t1_l1aocrt     False          NaN   \n",
       "\n",
       "    parent_id                                          permalink  \\\n",
       "0  t3_1cd9r3s  /r/AskPhysics/comments/1cd9r3s/keplers_constan...   \n",
       "\n",
       "   removal_reason replies  report_reasons  saved  score score_hidden  \\\n",
       "0             NaN     NaN             NaN  False    4.0        False   \n",
       "\n",
       "  send_replies stickied   subreddit subreddit_id subreddit_name_prefixed  \\\n",
       "0         True    False  AskPhysics     t5_2sumo            r/AskPhysics   \n",
       "\n",
       "  subreddit_type  top_awarded_type  total_awards_received treatment_tags  \\\n",
       "0         public               NaN                    0.0             []   \n",
       "\n",
       "   unrepliable_reason  ups user_reports kind         source date_scraped  \\\n",
       "0                 NaN  4.0           []   t1  askp-comments   2024-05-03   \n",
       "\n",
       "  scrape_num  \n",
       "0    scrape2  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate into one dataframe\n",
    "scrapes = pd.concat([scrapes, trouble], sort=False, axis=0, join='outer', ignore_index=True)\n",
    "print(f'scrapes is now a dataframe of dimensions {scrapes.shape}')\n",
    "scrapes.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53739bd-4543-4c98-a5e2-d102276620d3",
   "metadata": {},
   "source": [
    "In the \"behind the scenes\" work, because I was discovering the aforementioned problems and figuring out how to fix them as I went, I processed the batch of comments from each subreddit separately.  The can be found in the `data/input` folder, within `concatted-scrapes-separate-csvs-by-source.zip`.  Their file names begin with `askp` and `eli5`, respectively.\n",
    "\n",
    "For the purposes of demonstration, I will save the sample comments generated above into a CSV in the `data/output` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3a02e03a-4897-4ee3-a3b9-a5af1bb2b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the giant df as csv\n",
    "scrapes.to_csv(f'../data/output/concatted-wholes/comments-combined-as-of_{my_date()}.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d465eb-bea0-44b9-8365-178b7a53bcba",
   "metadata": {},
   "source": [
    "In this notebook, I have walked through my process for scraping, saving, and processing comments from each of my chosen subreddits.  In the next notebook, I will show how I combined them into one dataframe, and explain the feature selection and engineering process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
